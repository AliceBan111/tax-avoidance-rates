{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29dc5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    ShuffleSplit,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    RandomizedSearchCV,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    median_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score,\n",
    "    make_scorer\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbf0d8",
   "metadata": {},
   "source": [
    "# Part 1: Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b0cb82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 116)\n",
      "Index(['Unnamed: 0', 'Ticker', 'Nazwa2', 'rok', 'ta', 'txt', 'pi', 'str',\n",
      "       'xrd', 'ni',\n",
      "       ...\n",
      "       'intan_ma', 'ppe_ma', 'sale_ma', 'cash_holdings_ma', 'roa_past',\n",
      "       'lev_past', 'intan_past', 'ppe_past', 'sale_past',\n",
      "       'cash_holdings_past'],\n",
      "      dtype='object', length=116)\n",
      "   Unnamed: 0         Ticker             Nazwa2   rok         ta      txt  \\\n",
      "0           0  11B PW Equity  11 bit studios SA  2005  21.127613  1.24185   \n",
      "1           1  11B PW Equity  11 bit studios SA  2006  21.127613  1.24185   \n",
      "2           2  11B PW Equity  11 bit studios SA  2007  21.127613  1.24185   \n",
      "3           3  11B PW Equity  11 bit studios SA  2008  21.127613  1.24185   \n",
      "4           4  11B PW Equity  11 bit studios SA  2009  21.127613  1.24185   \n",
      "5           5  11B PW Equity  11 bit studios SA  2010   1.352400 -0.05370   \n",
      "6           6  11B PW Equity  11 bit studios SA  2011   2.986200  0.29240   \n",
      "7           7  11B PW Equity  11 bit studios SA  2012   7.336500  0.34030   \n",
      "8           8  11B PW Equity  11 bit studios SA  2013   8.712700  0.27590   \n",
      "9           9  11B PW Equity  11 bit studios SA  2014  21.515900  2.19100   \n",
      "\n",
      "          pi   str  xrd      ni  ...  intan_ma    ppe_ma   sale_ma  \\\n",
      "0   6.329725  0.19  0.0  5.0879  ...  0.198598  0.013076  0.445954   \n",
      "1   6.329725  0.19  0.0  5.0879  ...  0.198598  0.013076  0.445954   \n",
      "2   6.329725  0.19  0.0  5.0879  ...  0.198598  0.013076  0.445954   \n",
      "3   6.329725  0.19  0.0  5.0879  ...  0.198598  0.013076  0.445954   \n",
      "4   6.329725  0.19  0.0  5.0879  ...  0.198598  0.013076  0.445954   \n",
      "5  -0.284900  0.19  0.0 -0.2312  ...  0.198598  0.013076  0.445954   \n",
      "6   1.585100  0.19  0.0  1.2928  ...  0.599299  0.007352  0.223347   \n",
      "7   1.685000  0.19  0.0  1.3447  ...  0.508991  0.001182  0.292123   \n",
      "8   1.284300  0.19  0.0  1.0084  ...  0.011029  0.000859  0.479654   \n",
      "9  11.426700  0.19  0.0  9.2357  ...  0.028820  0.004118  0.388653   \n",
      "\n",
      "   cash_holdings_ma  roa_past  lev_past  intan_past  ppe_past  sale_past  \\\n",
      "0          0.574744  0.240818       0.0    0.198598  0.013076   0.445954   \n",
      "1          0.574744  0.240818       0.0    0.198598  0.013076   0.445954   \n",
      "2          0.574744  0.240818       0.0    0.198598  0.013076   0.445954   \n",
      "3          0.574744  0.240818       0.0    0.198598  0.013076   0.445954   \n",
      "4          0.574744  0.240818       0.0    0.198598  0.013076   0.445954   \n",
      "5          0.574744  0.240818       0.0    0.198598  0.013076   0.445954   \n",
      "6          0.557928 -0.170955       0.0    1.000000  0.001627   0.000739   \n",
      "7          0.488124  0.432925       0.0    0.017983  0.000737   0.583506   \n",
      "8          0.453777  0.183289       0.0    0.004076  0.000981   0.375801   \n",
      "9          0.450896  0.115739       0.0    0.053565  0.007254   0.401505   \n",
      "\n",
      "   cash_holdings_past  \n",
      "0            0.574744  \n",
      "1            0.574744  \n",
      "2            0.574744  \n",
      "3            0.574744  \n",
      "4            0.574744  \n",
      "5            0.574744  \n",
      "6            0.541112  \n",
      "7            0.435135  \n",
      "8            0.472419  \n",
      "9            0.429373  \n",
      "\n",
      "[10 rows x 116 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3993 entries, 0 to 3992\n",
      "Columns: 116 entries, Unnamed: 0 to cash_holdings_past\n",
      "dtypes: float64(57), int64(57), object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train_fe.csv')\n",
    "print(df_train.shape)\n",
    "print(df_train.columns)\n",
    "print(df_train.head(10))\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2580ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363, 116)\n",
      "   Unnamed: 0         Ticker                        Nazwa2   rok  \\\n",
      "0          11  11B PW Equity             11 bit studios SA  2016   \n",
      "1          23  1AT PW Equity                Atal SA/Poland  2016   \n",
      "2          35  4FM PW Equity                 4Fun Media SA  2016   \n",
      "3          47  AAL LN Equity            Anglo American PLC  2016   \n",
      "4          59  ABC PW Equity                   ABC Data SA  2016   \n",
      "5          71  ABE PW Equity                         AB SA  2016   \n",
      "6          83  ABF LN Equity  Associated British Foods PLC  2016   \n",
      "7          95  ABS PW Equity  Asseco Business Solutions SA  2016   \n",
      "8         107   AC FP Equity                      Accor SA  2016   \n",
      "9         119  ACG PW Equity                         Ac SA  2016   \n",
      "\n",
      "             ta          txt           pi     str     xrd            ni  ...  \\\n",
      "0  4.564940e+01     2.801500    15.730800  0.1900     0.0     12.929300  ...   \n",
      "1  1.513553e+03    15.915000   109.042999  0.1900     0.0     89.442001  ...   \n",
      "2  4.166300e+01     0.320200     1.489200  0.1900     0.0      1.346000  ...   \n",
      "3  5.014900e+04   698.000000  2624.000000  0.2000  1594.0  28719.000000  ...   \n",
      "4  1.252895e+03     5.019000    22.233000  0.1900     0.0     17.135000  ...   \n",
      "5  1.045349e+03    11.427334    52.442334  0.1900     0.0     41.004000  ...   \n",
      "6  1.137600e+04   221.000000  1042.000000  0.2000   818.0   5145.000000  ...   \n",
      "7  3.016820e+02    10.033000    52.479000  0.1900     0.0     42.445999  ...   \n",
      "8  1.382241e+06  1969.000000  6307.000000  0.3443     0.0   3874.000000  ...   \n",
      "9  1.311210e+02     7.526000    37.730000  0.1900     0.0     30.204000  ...   \n",
      "\n",
      "   intan_ma    ppe_ma   sale_ma  cash_holdings_ma  roa_past  lev_past  \\\n",
      "0  0.130887  0.009081  0.539652          0.527618  0.352416  0.000000   \n",
      "1  0.066162  0.007559  0.360836          0.100509  0.039084  0.196057   \n",
      "2  0.496920  0.087819  0.470287          0.056824  0.067262  0.014443   \n",
      "3  0.062258  0.001563  0.337668          0.117395  0.569492  0.345433   \n",
      "4  0.045939  0.005163  1.820588          0.032882  0.043842  0.090251   \n",
      "5  0.039714  0.110957  1.664921          0.038581  0.035124  0.180192   \n",
      "6  0.136929  0.003625  0.808372          0.059128  0.442118  0.087680   \n",
      "7  0.632498  0.035856  0.416575          0.171175  0.115533  0.000000   \n",
      "8  0.004504  0.012910  0.032015          0.051250  0.002998  0.315137   \n",
      "9  0.014629  0.480603  0.822036          0.106419  0.206658  0.000000   \n",
      "\n",
      "   intan_past  ppe_past  sale_past  cash_holdings_past  \n",
      "0    0.194652  0.013346   0.534162            0.699963  \n",
      "1    0.052127  0.006567   0.171832            0.107148  \n",
      "2    0.564584  0.152826   0.469210            0.042710  \n",
      "3    0.065253  0.001596   0.331651            0.132563  \n",
      "4    0.043249  0.004455   1.713010            0.030002  \n",
      "5    0.037394  0.101637   1.630523            0.014571  \n",
      "6    0.133770  0.003621   0.812071            0.068696  \n",
      "7    0.626312  0.035433   0.421007            0.140181  \n",
      "8    0.004481  0.013339   0.033334            0.058877  \n",
      "9    0.016379  0.447505   0.790320            0.128360  \n",
      "\n",
      "[10 rows x 116 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test_fe.csv')\n",
    "print(df_test.shape)\n",
    "print(df_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0bda747",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    df_train['etr'] > 0.25,\n",
    "    df_train['etr'] <= 0.15\n",
    "]\n",
    "\n",
    "choices = [0, 2]\n",
    "\n",
    "df_train['etr_classification'] = np.select(conditions, choices, default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19221b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Summary:\n",
      "Class 0: 1267 records (31.73%)\n",
      "Class 1: 1668 records (41.77%)\n",
      "Class 2: 1058 records (26.5%)\n"
     ]
    }
   ],
   "source": [
    "etr_summary = df_train.groupby('etr_classification').size()\n",
    "etr_summary_pct = (etr_summary / len(df_train) * 100).round(2)\n",
    "\n",
    "print(\"Classification Summary:\")\n",
    "for class_val, count in etr_summary.items():\n",
    "    pct = etr_summary_pct[class_val]\n",
    "    print(f\"Class {class_val}: {count} records ({pct}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dfd95a",
   "metadata": {},
   "source": [
    "There exists imbalance in the dataset, with class1 having significantly more samples than class2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4d61fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    df_test['etr'] > 0.25,\n",
    "    df_test['etr'] <= 0.15\n",
    "]\n",
    "\n",
    "choices = [0, 2]\n",
    "\n",
    "df_test['etr_classification'] = np.select(conditions, choices, default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aff78b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for multi-class target (ANOVA F-value):\n",
      "                     feature     f_score        p_value\n",
      "98                  etr_y_ma  473.525179  2.972696e-185\n",
      "63   str_cat_(0.0875, 0.192]  454.959863  1.032622e-178\n",
      "32                  WB_GDPpc  408.775301  3.182863e-162\n",
      "4                        str  380.545761  5.471431e-152\n",
      "65       str_cat_(0.28, inf]  364.313099  4.773705e-146\n",
      "..                       ...         ...            ...\n",
      "38             sektor_energy    0.526236   5.908658e-01\n",
      "48                  gielda_5    0.510716   6.001050e-01\n",
      "74  dltt_cat_(39.38, 327.85]    0.428391   6.515865e-01\n",
      "93        cash_holdings_sqrt    0.350097   7.046412e-01\n",
      "30            y_BR_Democracy         NaN            NaN\n",
      "\n",
      "[112 rows x 3 columns]\n",
      "\n",
      "Significant features (p < 0.05): ['etr_y_ma', 'str_cat_(0.0875, 0.192]', 'WB_GDPpc', 'str', 'str_cat_(0.28, inf]', 'cfc', 'etr_y_past', 'revenue_cat_(0.174, 1248.817]', 'xrd_exists', 'ta_log', 'cce_cat_(63.321, inf]', 'txt_cat_(0.488, 24.415]', 'pi_cat_(-1.523, 157.119]', 'dlc_cat_(200.9, inf]', 'gielda_2', 'revenue_cat_(4233.587, inf]', 'intant_sqrt', 'txt_cat_(-34.811, 0.488]', 'diff_positive', 'rd_sqrt', 'pi_cat_(465.9, 7875.5]', 'WB_GDPgrowth', 'dta', 'cfc_dta', 'txt_cat_(25.05, 308.55]', 'capex_cat_(79.55, 5451.0]', 'cce_cat_(5.619, 63.321]', 'txt_cat_(327.531, inf]', 'pi_cat_(-8975.0, -1.523]', 'dltt_cat_(876.617, inf]', 'gielda_4', 'y_e_p_polity', 'ni_profit', 'intant', 'txt', 'ppe_ma', 'ppe_past', 'intan', 'ppe_clip', 'ppe', 'intan_ma', 'intan_past', 'pi', 'rd', 'revenue', 'capex', 'ppent_sqrt', 'sale', 'sale_ma', 'sale_past', 'dlc_cat_(42.262, 176.129]', 'gielda_3', 'lev', 'pi_cat_(157.119, 465.9]', 'ni', 'intan_pow2', 'xrd', 'lev_sqrt', 'cce', 'sektor_real estate', 'txt_cat_(308.55, 327.531]', 'ppent', 'adv_cat_(874.5, inf]', 'pi_cat_(8108.5, inf]', 'capex_cat_(5451.0, inf]', 'adv_expenditure', 'adv', 'str_cat_(0.192, 0.28]', 'dlc', 'lev_ma', 'ni_profit_20000', 'lev_past', 'ta', 'revenue_cat_(1248.817, 4233.587]', 'roa', 'roa_clip', 'adv_expenditure_positive', 'capex_cat_(7.447, 79.55]', 'sektor_industrials', 'roa_ma', 'roa_past', 'rr_per_country', 'sektor_consumer staples', 'dlc_cat_(176.129, 200.9]', 'diff_dta', 'sektor_materials', 'dltt', 'dltt_cat_(327.85, 876.617]', 'WB_Inflation', 'sektor_consumer discretionary', 'capex2_scaled', 'capex2', 'txt_cat_(-63.011, -34.811]']\n",
      "Top 10 features: ['etr_y_ma', 'str_cat_(0.0875, 0.192]', 'WB_GDPpc', 'str', 'str_cat_(0.28, inf]', 'cfc', 'etr_y_past', 'revenue_cat_(0.174, 1248.817]', 'xrd_exists', 'ta_log']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: UserWarning: Features [30] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\hp\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "X_train = df_train.drop(columns=['etr', 'etr_classification','Ticker','Nazwa2',\"Unnamed: 0\"])\n",
    "y_train = df_train['etr_classification']\n",
    "\n",
    "f_scores, p_values = f_classif(X_train, y_train)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'f_score': f_scores,\n",
    "    'p_value': p_values\n",
    "}).sort_values('f_score', ascending=False)\n",
    "\n",
    "print(\"Feature importance for multi-class target (ANOVA F-value):\")\n",
    "print(feature_importance)\n",
    "\n",
    "significant_features = feature_importance[feature_importance['p_value'] < 0.05]['feature'].tolist()\n",
    "print(f\"\\nSignificant features (p < 0.05): {significant_features}\")\n",
    "\n",
    "top_k_features = feature_importance.head(10)['feature'].tolist()\n",
    "print(f\"Top 10 features: {top_k_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75a3ff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top features by Mutual Information:\n",
      "              feature  mi_score\n",
      "97         etr_y_past  0.293676\n",
      "98           etr_y_ma  0.283371\n",
      "99            diff_ma  0.178419\n",
      "2                 txt  0.172439\n",
      "102          intan_ma  0.169218\n",
      "70        intant_sqrt  0.167975\n",
      "15               diff  0.167096\n",
      "8              intant  0.166209\n",
      "6                  ni  0.165523\n",
      "3                  pi  0.163908\n",
      "104           sale_ma  0.144568\n",
      "105  cash_holdings_ma  0.138192\n",
      "103            ppe_ma  0.138118\n",
      "1                  ta  0.136832\n",
      "12            revenue  0.136394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mi_scores = mutual_info_classif(X_train, y_train, random_state=42)\n",
    "\n",
    "mi_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'mi_score': mi_scores\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "print(\"\\nTop features by Mutual Information:\")\n",
    "print(mi_importance.head(15))\n",
    "\n",
    "top_features_mi = mi_importance.head(20)['feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2fb6670b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: UserWarning: Features [30] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\hp\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['etr_y_ma', 'etr_y_past', 'str', 'intant_sqrt', 'ta_log', 'txt', 'intant', 'str_cat_(0.0875, 0.192]', 'WB_GDPpc', 'intan_ma', 'ppe_ma', 'str_cat_(0.28, inf]', 'cfc']\n"
     ]
    }
   ],
   "source": [
    "def combined_feature_ranking(X_train, y_train, top_k=15):\n",
    "    f_scores, p_values = f_classif(X_train, y_train)\n",
    "\n",
    "    mi_scores = mutual_info_classif(X_train, y_train, random_state=42)\n",
    "\n",
    "    combined_df = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'f_score': f_scores,\n",
    "        'f_rank': pd.Series(f_scores).rank(ascending=False),\n",
    "        'mi_score': mi_scores,\n",
    "        'mi_rank': pd.Series(mi_scores).rank(ascending=False),\n",
    "        'p_value': p_values\n",
    "    })\n",
    "\n",
    "    combined_df['combined_rank'] = combined_df['f_rank'] + combined_df['mi_rank']\n",
    "    combined_df = combined_df.sort_values('combined_rank')\n",
    "\n",
    "    significant_combined = combined_df[\n",
    "        (combined_df['p_value'] < 0.05) & \n",
    "        (combined_df['combined_rank'] <= top_k * 2)  \n",
    "    ].sort_values('combined_rank')\n",
    "    \n",
    "    return significant_combined.head(top_k)\n",
    "\n",
    "selected_features_df = combined_feature_ranking(X_train, y_train, top_k=25)\n",
    "selected_features = selected_features_df['feature'].tolist()\n",
    "print(f\"Selected features: {selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e16c461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated feature pairs: 3\n",
      "  str - str_cat_(0.28, inf]: 0.847\n",
      "  intant_sqrt - intant: 0.923\n",
      "  str_cat_(0.0875, 0.192] - WB_GDPpc: 0.943\n"
     ]
    }
   ],
   "source": [
    "selected_X = X_train[selected_features]\n",
    "corr_matrix = selected_X.corr().abs()\n",
    "\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if corr_matrix.iloc[i, j] > 0.8:  \n",
    "            high_corr_pairs.append((\n",
    "                corr_matrix.columns[i],\n",
    "                corr_matrix.columns[j],\n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "print(f\"Highly correlated feature pairs: {len(high_corr_pairs)}\")\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\"  {pair[0]} - {pair[1]}: {pair[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9975daf",
   "metadata": {},
   "source": [
    "As the score of str_cat_(0.0875, 0.192] is higher than WB_GDPpc, I will keep str_cat_(0.0875, 0.192] and drop WB_GDPpc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bfacdbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_final = ['etr_y_ma', 'etr_y_past', 'ta_log', 'txt', 'intant', 'str_cat_(0.0875, 0.192]', 'intan_ma', 'ppe_ma', 'cfc','str_cat_(0.28, inf]']\n",
    "\n",
    "X_train_selected = df_train[selected_features_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5f8a797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_selected = df_test[selected_features_final]\n",
    "y_test = df_test['etr_classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81764a3c",
   "metadata": {},
   "source": [
    "# Part 2: Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33629c4f",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ca07536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ff5a815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression result:\n",
      "Accuracy: 0.5813\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.63      0.56       103\n",
      "           1       0.73      0.59      0.65       195\n",
      "           2       0.41      0.48      0.44        65\n",
      "\n",
      "    accuracy                           0.58       363\n",
      "   macro avg       0.55      0.57      0.55       363\n",
      "weighted avg       0.61      0.58      0.59       363\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 65  25  13]\n",
      " [ 49 115  31]\n",
      " [ 17  17  31]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "multi_lr = LogisticRegression(\n",
    "    multi_class='multinomial',  \n",
    "    solver='lbfgs',            \n",
    "    max_iter=1000,             \n",
    "    random_state=42,\n",
    "    C=1.0                      \n",
    ")\n",
    "\n",
    "multi_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = multi_lr.predict(X_test_scaled)\n",
    "y_pred_proba = multi_lr.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"Logistic regression result:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec182b0",
   "metadata": {},
   "source": [
    "Class 1 performs the best in terms of precision and F1-score. The overall accuray is 0.5813, which is not very high. The model seems to struggle with class 0 and class 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9244ae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: Train Sample 668, Validation Sample 665\n",
      "  Fold 2: Train Sample 1333, Validation Sample 665\n",
      "  Fold 3: Train Sample 1998, Validation Sample 665\n",
      "  Fold 4: Train Sample 2663, Validation Sample 665\n",
      "  Fold 5: Train Sample 3328, Validation Sample 665\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "   Best parameter: {'logreg__C': 0.01, 'logreg__class_weight': None, 'logreg__solver': 'newton-cg'}\n",
      "   Best time series CV score: 0.6081\n",
      "   Time series CV accuracy: 0.6081 (±0.0232)\n",
      "     Fold 1: 0.6060\n",
      "     Fold 2: 0.6406\n",
      "     Fold 3: 0.6105\n",
      "     Fold 4: 0.5684\n",
      "     Fold 5: 0.6150\n",
      "Performance on Test Set:\n",
      "Accuracy:                0.5868\n",
      "Precision (weighted):    0.6109\n",
      "Recall (weighted):       0.5868\n",
      "F1-Score (weighted):     0.5926\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.63      0.55       103\n",
      "           1       0.73      0.60      0.66       195\n",
      "           2       0.45      0.48      0.46        65\n",
      "\n",
      "    accuracy                           0.59       363\n",
      "   macro avg       0.56      0.57      0.56       363\n",
      "weighted avg       0.61      0.59      0.59       363\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 65  26  12]\n",
      " [ 52 117  26]\n",
      " [ 17  17  31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "def complete_modeling_pipeline_timeseries(X_train_selected, y_train, X_test_selected, y_test, n_splits=5):\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train_selected)):\n",
    "        print(f\"  Fold {fold+1}: Train Sample {len(train_idx)}, Validation Sample {len(val_idx)}\")\n",
    "    \n",
    "    # 1. Hyperparameter tuning with Time Series CV\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logreg', LogisticRegression(multi_class='multinomial', random_state=42, max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'logreg__C': [0.01, 0.1, 1, 10],\n",
    "        'logreg__solver': ['lbfgs', 'newton-cg'],\n",
    "        'logreg__class_weight': [None, 'balanced']\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=tscv,  \n",
    "        scoring='accuracy', \n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    print(f\"   Best parameter: {grid_search.best_params_}\")\n",
    "    print(f\"   Best time series CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    best_lr = grid_search.best_estimator_\n",
    "\n",
    "    cv_scores = cross_val_score(best_lr, X_train_selected, y_train, cv=tscv)\n",
    "    print(f\"   Time series CV accuracy: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "\n",
    "    for i, score in enumerate(cv_scores):\n",
    "        print(f\"     Fold {i+1}: {score:.4f}\")\n",
    "    \n",
    "    # 2. Final evaluation on the test set\n",
    "    print(\"Performance on Test Set:\")\n",
    "\n",
    "    y_pred = best_lr.predict(X_test_selected)\n",
    "\n",
    "    print(f\"Accuracy:                {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision (weighted):    {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"Recall (weighted):       {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"F1-Score (weighted):     {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return best_model, grid_search, cv_scores\n",
    "\n",
    "best_model, grid_search, cv_scores = complete_modeling_pipeline_timeseries(\n",
    "    X_train_selected, y_train, X_test_selected, y_test, n_splits=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cbac66",
   "metadata": {},
   "source": [
    "The model improves slightly after hyperparameter tuning, but the overall performance is still not very satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533f9b0",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9fdefd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors result:\n",
      "Accuracy: 0.5950\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.56       103\n",
      "           1       0.69      0.65      0.67       195\n",
      "           2       0.43      0.49      0.46        65\n",
      "\n",
      "    accuracy                           0.60       363\n",
      "   macro avg       0.56      0.57      0.56       363\n",
      "weighted avg       0.60      0.60      0.60       363\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 58  32  13]\n",
      " [ 40 126  29]\n",
      " [  8  25  32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=8)  \n",
    "\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "y_pred_proba = knn.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"K-Nearest Neighbors result:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e524e6e",
   "metadata": {},
   "source": [
    "This model performs slightly better than logistic regression in terms of accuracy, but still struggles with class 0 and class 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "649cf69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.14.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\hp\\.conda\\envs\\myenv\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.3)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\hp\\.conda\\envs\\myenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\hp\\.conda\\envs\\myenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\hp\\.conda\\envs\\myenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\hp\\.conda\\envs\\myenv\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.14.0-py3-none-any.whl (239 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.14.0 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "73e2b8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 1: Using SMOTE for oversampling minority classes...\n",
      "Original training set size: 3993\n",
      "After SMOTE: 5004\n",
      "Class distribution after SMOTE:\n",
      "  Class 0: 1668 records (33.33%)\n",
      "  Class 1: 1668 records (33.33%)\n",
      "  Class 2: 1668 records (33.33%)\n",
      "\n",
      "\n",
      "Strategy 2: Using SMOTE + Random Undersampling...\n",
      "After SMOTE + Undersampling: 4200\n",
      "Class distribution after combined resampling:\n",
      "  Class 0: 1400 records (33.33%)\n",
      "  Class 1: 1400 records (33.33%)\n",
      "  Class 2: 1400 records (33.33%)\n",
      "Hyperparameter Tuning with SMOTE-resampled Data\n",
      "\n",
      "Performing hyperparameter tuning...\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "\n",
      "============================================================\n",
      "Best Hyperparameters:\n",
      "{'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "Best cross-validation F1-weighted score: 0.6787\n",
      "============================================================\n",
      "\n",
      "Cross-Validation Results on Training Set (TimeSeriesSplit, 5 folds):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:      0.9890 (+/- 0.0007)\n",
      "Validation Accuracy:    0.6705 (+/- 0.0608)\n",
      "Validation Precision:   0.7043 (+/- 0.1118)\n",
      "Validation Recall:      0.6705 (+/- 0.0608)\n",
      "Validation F1-Score:    0.6787 (+/- 0.0861)\n",
      "\n",
      "Performance on Test Set:\n",
      "Accuracy:                0.5978\n",
      "Precision (weighted):    0.6342\n",
      "Recall (weighted):       0.5978\n",
      "F1-Score (weighted):     0.6078\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58       103\n",
      "           1       0.73      0.61      0.67       195\n",
      "           2       0.38      0.62      0.47        65\n",
      "\n",
      "    accuracy                           0.60       363\n",
      "   macro avg       0.57      0.60      0.57       363\n",
      "weighted avg       0.63      0.60      0.61       363\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 58  25  20]\n",
      " [ 31 119  45]\n",
      " [  7  18  40]]\n",
      "Top 10 GridSearchCV Results:\n",
      " param_n_neighbors param_weights param_metric  mean_test_score  std_test_score\n",
      "                 3       uniform    euclidean         0.638075        0.100847\n",
      "                 3      distance    euclidean         0.652503        0.135273\n",
      "                 5       uniform    euclidean         0.635625        0.075832\n",
      "                 5      distance    euclidean         0.666598        0.119101\n",
      "                 7       uniform    euclidean         0.637119        0.066934\n",
      "                 7      distance    euclidean         0.667000        0.110147\n",
      "                 9       uniform    euclidean         0.636782        0.064936\n",
      "                 9      distance    euclidean         0.671033        0.103551\n",
      "                11       uniform    euclidean         0.641785        0.062141\n",
      "                11      distance    euclidean         0.670824        0.099590\n",
      "Comparison: Different Resampling Strategies\n",
      "\n",
      "SMOTE only - F1-weighted: 0.6078\n",
      "SMOTE + Undersampling - F1-weighted: 0.5778\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Step 1: Create imbalanced data handling strategies\n",
    "\n",
    "# Strategy 1: SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "print(\"\\nStrategy 1: Using SMOTE for oversampling minority classes...\")\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "print(f\"Original training set size: {X_train_scaled.shape[0]}\")\n",
    "print(f\"After SMOTE: {X_train_smote.shape[0]}\")\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "unique, counts = np.unique(y_train_smote, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {count} records ({count/len(y_train_smote)*100:.2f}%)\")\n",
    "\n",
    "# Strategy 2: Combination of SMOTE and undersampling\n",
    "print(\"\\n\\nStrategy 2: Using SMOTE + Random Undersampling...\")\n",
    "# First oversample minority classes to match majority class (1668)\n",
    "sampling_strategy_oversample = {0: 1668, 2: 1668}\n",
    "# Then undersample majority class\n",
    "sampling_strategy_undersample = {1: 1400, 0: 1400, 2: 1400}\n",
    "smote_combined = SMOTE(sampling_strategy=sampling_strategy_oversample, random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=sampling_strategy_undersample, random_state=42)\n",
    "X_train_combined, y_train_combined = smote_combined.fit_resample(X_train_scaled, y_train)\n",
    "X_train_combined, y_train_combined = under.fit_resample(X_train_combined, y_train_combined)\n",
    "print(f\"After SMOTE + Undersampling: {X_train_combined.shape[0]}\")\n",
    "print(\"Class distribution after combined resampling:\")\n",
    "unique, counts = np.unique(y_train_combined, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {count} records ({count/len(y_train_combined)*100:.2f}%)\")\n",
    "\n",
    "# Step 2: Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15, 21],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Step 3: Use GridSearchCV with TimeSeriesSplit for hyperparameter tuning\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "print(\"Hyperparameter Tuning with SMOTE-resampled Data\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='f1_weighted',  # Using F1-weighted score for imbalanced data\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nPerforming hyperparameter tuning...\")\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best cross-validation F1-weighted score: {grid_search.best_score_:.4f}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Step 4: Get best model\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Step 5: Detailed cross-validation evaluation on training set\n",
    "print(\"Cross-Validation Results on Training Set (TimeSeriesSplit, 5 folds):\")\n",
    "cv_results = cross_validate(\n",
    "    best_knn,\n",
    "    X_train_smote,\n",
    "    y_train_smote,\n",
    "    cv=tscv,\n",
    "    scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'],\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"Training Accuracy:      {cv_results['train_accuracy'].mean():.4f} (+/- {cv_results['train_accuracy'].std():.4f})\")\n",
    "print(f\"Validation Accuracy:    {cv_results['test_accuracy'].mean():.4f} (+/- {cv_results['test_accuracy'].std():.4f})\")\n",
    "print(f\"Validation Precision:   {cv_results['test_precision_weighted'].mean():.4f} (+/- {cv_results['test_precision_weighted'].std():.4f})\")\n",
    "print(f\"Validation Recall:      {cv_results['test_recall_weighted'].mean():.4f} (+/- {cv_results['test_recall_weighted'].std():.4f})\")\n",
    "print(f\"Validation F1-Score:    {cv_results['test_f1_weighted'].mean():.4f} (+/- {cv_results['test_f1_weighted'].std():.4f})\\n\")\n",
    "\n",
    "# Step 6: Evaluate on test set\n",
    "print(\"Performance on Test Set:\")\n",
    "\n",
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "y_pred_proba = best_knn.predict_proba(X_test_scaled)\n",
    "\n",
    "print(f\"Accuracy:                {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision (weighted):    {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall (weighted):       {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1-Score (weighted):     {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 7: Print top 10 GridSearchCV results\n",
    "print(\"Top 10 GridSearchCV Results:\")\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_results = results_df[['param_n_neighbors', 'param_weights', 'param_metric', 'mean_test_score', 'std_test_score']].head(10)\n",
    "print(top_results.to_string(index=False))\n",
    "\n",
    "# Step 8: Compare models trained on different resampled datasets\n",
    "print(\"Comparison: Different Resampling Strategies\")\n",
    "\n",
    "# Train on SMOTE data\n",
    "y_pred_smote = best_knn.predict(X_test_scaled)\n",
    "f1_smote = f1_score(y_test, y_pred_smote, average='weighted')\n",
    "print(f\"\\nSMOTE only - F1-weighted: {f1_smote:.4f}\")\n",
    "\n",
    "# Retrain on combined resampling\n",
    "grid_search_combined = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "grid_search_combined.fit(X_train_combined, y_train_combined)\n",
    "best_knn_combined = grid_search_combined.best_estimator_\n",
    "y_pred_combined = best_knn_combined.predict(X_test_scaled)\n",
    "f1_combined = f1_score(y_test, y_pred_combined, average='weighted')\n",
    "print(f\"SMOTE + Undersampling - F1-weighted: {f1_combined:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2dd59",
   "metadata": {},
   "source": [
    "KNN also improves after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6634c",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "30213dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Performance on Test Set:\n",
      "Accuracy:                0.6364\n",
      "Precision (weighted):    0.6561\n",
      "Recall (weighted):       0.6364\n",
      "F1-Score (weighted):     0.6435\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.61       103\n",
      "           1       0.76      0.69      0.72       195\n",
      "           2       0.41      0.54      0.46        65\n",
      "\n",
      "    accuracy                           0.64       363\n",
      "   macro avg       0.59      0.61      0.60       363\n",
      "weighted avg       0.66      0.64      0.64       363\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 62  22  19]\n",
      " [ 29 134  32]\n",
      " [ 10  20  35]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Train a basic SVC model\n",
    "svc = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 2: Make predictions\n",
    "y_pred = svc.predict(X_test_scaled)\n",
    "y_pred_proba = svc.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"SVC Performance on Test Set:\")\n",
    "\n",
    "print(f\"Accuracy:                {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision (weighted):    {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall (weighted):       {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1-Score (weighted):     {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "44024b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling Class Imbalance with SMOTE\n",
      "Original training set size: 3993\n",
      "After SMOTE: 5004\n",
      "Class distribution after SMOTE:\n",
      "  Class 0: 1668 records (33.33%)\n",
      "  Class 1: 1668 records (33.33%)\n",
      "  Class 2: 1668 records (33.33%)\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Hyperparameters:\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best cross-validation F1-weighted score: 0.6543\n",
      "Cross-Validation Results on Training Set\n",
      "(TimeSeriesSplit, 5 folds)\n",
      "\n",
      "Training Set Performance:\n",
      "  Accuracy:   0.7471 (+/- 0.0226)\n",
      "  Precision:  0.7486 (+/- 0.0232)\n",
      "  Recall:     0.7471 (+/- 0.0226)\n",
      "  F1-Score:   0.7457 (+/- 0.0224)\n",
      "\n",
      "Validation Set Performance:\n",
      "  Accuracy:   0.6391 (+/- 0.0432)\n",
      "  Precision:  0.6873 (+/- 0.1198)\n",
      "  Recall:     0.6391 (+/- 0.0432)\n",
      "  F1-Score:   0.6543 (+/- 0.0697)\n",
      "Performance on Test Set:\n",
      "Accuracy:                0.6253\n",
      "Precision (weighted):    0.6625\n",
      "Recall (weighted):       0.6253\n",
      "F1-Score (weighted):     0.6359\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       103\n",
      "           1       0.78      0.64      0.70       195\n",
      "           2       0.40      0.62      0.48        65\n",
      "\n",
      "    accuracy                           0.63       363\n",
      "   macro avg       0.60      0.62      0.60       363\n",
      "weighted avg       0.66      0.63      0.64       363\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 63  21  19]\n",
      " [ 30 124  41]\n",
      " [ 11  14  40]]\n",
      "Top 10 GridSearchCV Results:\n",
      " param_C param_kernel param_gamma  mean_test_score  std_test_score\n",
      "       1          rbf       scale         0.644877        0.039317\n",
      "       1         poly       scale         0.617144        0.047713\n",
      "      10          rbf       scale         0.654331        0.069735\n",
      "      10         poly       scale         0.628682        0.061872\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Handle class imbalance with SMOTE\n",
    "print(\"Handling Class Imbalance with SMOTE\")\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Original training set size: {X_train_scaled.shape[0]}\")\n",
    "print(f\"After SMOTE: {X_train_smote.shape[0]}\")\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "unique, counts = np.unique(y_train_smote, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {count} records ({count/len(y_train_smote)*100:.2f}%)\")\n",
    "\n",
    "# Step 2: Define hyperparameter grid for SVC\n",
    "param_grid = {\n",
    "    'C': [1,10],\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'gamma': ['scale'],\n",
    "}\n",
    "\n",
    "# Step 3: Use GridSearchCV with TimeSeriesSplit for hyperparameter tuning\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(random_state=42, probability=True),\n",
    "    param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best cross-validation F1-weighted score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Step 4: Get best model\n",
    "best_svc = grid_search.best_estimator_\n",
    "\n",
    "# Step 5: Detailed cross-validation evaluation on training set\n",
    "print(\"Cross-Validation Results on Training Set\")\n",
    "print(\"(TimeSeriesSplit, 5 folds)\")\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    best_svc,\n",
    "    X_train_smote,\n",
    "    y_train_smote,\n",
    "    cv=tscv,\n",
    "    scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'],\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Set Performance:\")\n",
    "print(f\"  Accuracy:   {cv_results['train_accuracy'].mean():.4f} (+/- {cv_results['train_accuracy'].std():.4f})\")\n",
    "print(f\"  Precision:  {cv_results['train_precision_weighted'].mean():.4f} (+/- {cv_results['train_precision_weighted'].std():.4f})\")\n",
    "print(f\"  Recall:     {cv_results['train_recall_weighted'].mean():.4f} (+/- {cv_results['train_recall_weighted'].std():.4f})\")\n",
    "print(f\"  F1-Score:   {cv_results['train_f1_weighted'].mean():.4f} (+/- {cv_results['train_f1_weighted'].std():.4f})\")\n",
    "\n",
    "print(\"\\nValidation Set Performance:\")\n",
    "print(f\"  Accuracy:   {cv_results['test_accuracy'].mean():.4f} (+/- {cv_results['test_accuracy'].std():.4f})\")\n",
    "print(f\"  Precision:  {cv_results['test_precision_weighted'].mean():.4f} (+/- {cv_results['test_precision_weighted'].std():.4f})\")\n",
    "print(f\"  Recall:     {cv_results['test_recall_weighted'].mean():.4f} (+/- {cv_results['test_recall_weighted'].std():.4f})\")\n",
    "print(f\"  F1-Score:   {cv_results['test_f1_weighted'].mean():.4f} (+/- {cv_results['test_f1_weighted'].std():.4f})\")\n",
    "\n",
    "# Step 6: Evaluate on test set\n",
    "print(\"Performance on Test Set:\")\n",
    "\n",
    "y_pred = best_svc.predict(X_test_scaled)\n",
    "y_pred_proba = best_svc.predict_proba(X_test_scaled)\n",
    "\n",
    "print(f\"Accuracy:                {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision (weighted):    {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall (weighted):       {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1-Score (weighted):     {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 7: Print top 10 GridSearchCV results\n",
    "print(\"Top 10 GridSearchCV Results:\")\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_results = results_df[['param_C', 'param_kernel', 'param_gamma', 'mean_test_score', 'std_test_score']].head(10)\n",
    "print(top_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb5553",
   "metadata": {},
   "source": [
    "# 3. Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "95b88471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison on Test Set\n",
      "\n",
      "              Model  Accuracy  Precision   Recall  F1-Score\n",
      "Logistic Regression  0.586777   0.610907 0.586777  0.592583\n",
      "                KNN  0.597796   0.634247 0.597796  0.607792\n",
      "                SVC  0.625344   0.662451 0.625344  0.635870\n",
      "\n",
      "Sorted by F1-Score (descending)\n",
      "\n",
      "              Model  Accuracy  Precision   Recall  F1-Score\n",
      "                SVC  0.625344   0.662451 0.625344  0.635870\n",
      "                KNN  0.597796   0.634247 0.597796  0.607792\n",
      "Logistic Regression  0.586777   0.610907 0.586777  0.592583\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model_comparison = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
    "\n",
    "# Logistic Regression\n",
    "y_pred_lr = best_model.predict(X_test_selected)\n",
    "model_comparison.loc[len(model_comparison)] = [\n",
    "    'Logistic Regression',\n",
    "    accuracy_score(y_test, y_pred_lr),\n",
    "    precision_score(y_test, y_pred_lr, average='weighted'),\n",
    "    recall_score(y_test, y_pred_lr, average='weighted'),\n",
    "    f1_score(y_test, y_pred_lr, average='weighted')\n",
    "]\n",
    "\n",
    "# KNN\n",
    "y_pred_knn = best_knn.predict(X_test_scaled)\n",
    "model_comparison.loc[len(model_comparison)] = [\n",
    "    'KNN',\n",
    "    accuracy_score(y_test, y_pred_knn),\n",
    "    precision_score(y_test, y_pred_knn, average='weighted'),\n",
    "    recall_score(y_test, y_pred_knn, average='weighted'),\n",
    "    f1_score(y_test, y_pred_knn, average='weighted')\n",
    "]\n",
    "# SVC\n",
    "\n",
    "y_pred_svc = best_svc.predict(X_test_scaled)\n",
    "model_comparison.loc[len(model_comparison)] = [\n",
    "    'SVC',\n",
    "    accuracy_score(y_test, y_pred_svc),\n",
    "    precision_score(y_test, y_pred_svc, average='weighted'),\n",
    "    recall_score(y_test, y_pred_svc, average='weighted'),\n",
    "    f1_score(y_test, y_pred_svc, average='weighted')\n",
    "]\n",
    "\n",
    "\n",
    "print(\"\\nModel Performance Comparison on Test Set\\n\")\n",
    "print(model_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\nSorted by F1-Score (descending)\\n\")\n",
    "print(model_comparison.sort_values(by='F1-Score', ascending=False).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4667dd47",
   "metadata": {},
   "source": [
    "SVC performs the best among the three models, with an accuracy of 0.6253 and better precision and F1-scores across all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "363bc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "with open(\"model/best_svc.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_svc, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
